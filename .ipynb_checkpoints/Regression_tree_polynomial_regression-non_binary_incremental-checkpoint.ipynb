{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#blob\n",
    "\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/blob_att.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row])\n",
    "        \n",
    "with open(\"DataSets/blob_label.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        y_training.append(int(row[0]))\n",
    "#print(X_training)\n",
    "#print(y_training)\n",
    "        \n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "#all_data.append([X_train, X_test, y_train, y_test,header])\n",
    "\n",
    "\n",
    "batch_x = []\n",
    "batch_y = []\n",
    "\n",
    "a = len(X_train)\n",
    "step = 1000\n",
    "\n",
    "for i in range(0, a, step):\n",
    "\n",
    "\n",
    "    #for j in range(i, i + step):\n",
    "        batch_x.append(X_train[i:i + step])\n",
    "        batch_y.append(y_train[i:i + step])\n",
    "print(len(batch_x))\n",
    "all_data.append([batch_x, X_test, batch_y, y_test,header])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/iris.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row[:-1]\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row[:-1]])\n",
    "        y_training.append(row[-1])\n",
    "        #print(row)\n",
    "\n",
    "for i in range(len(y_training)):\n",
    "    if(y_training[i] == \"Setosa\"):\n",
    "        y_training[i] = 1\n",
    "    if(y_training[i] == \"Versicolor\"):\n",
    "        y_training[i] = 2\n",
    "    if(y_training[i] == \"Virginica\"):\n",
    "        y_training[i] = 3\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "#all_data.append([X_train, X_test, y_train, y_test,header])\n",
    "\n",
    "\n",
    "\n",
    "batch_x = []\n",
    "batch_y = []\n",
    "\n",
    "a = len(X_train)\n",
    "step = 10\n",
    "\n",
    "for i in range(0, a, step):\n",
    "\n",
    "\n",
    "    #for j in range(i, i + step):\n",
    "        batch_x.append(X_train[i:i + step])\n",
    "        batch_y.append(y_train[i:i + step])\n",
    "\n",
    "all_data.append([batch_x, X_test, batch_y, y_test,header])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed acidity', '\"volatile acidity\"', '\"citric acid\"', '\"residual sugar\"', '\"chlorides\"', '\"free sulfur dioxide\"', '\"total sulfur dioxide\"', '\"density\"', '\"pH\"', '\"sulphates\"', '\"alcohol\"']\n",
      "4898\n",
      "4898\n"
     ]
    }
   ],
   "source": [
    "#wine\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/winequality-white_att.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row[:-1]])\n",
    "        y_training.append(float(row[-1]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "#all_data.append([X_train, X_test, y_train, y_test,header])\n",
    "print(header)\n",
    "print(len(X_training))\n",
    "print(len(y_training))\n",
    "\n",
    "\n",
    "\n",
    "batch_x = []\n",
    "batch_y = []\n",
    "\n",
    "a = len(X_train)\n",
    "step = 480\n",
    "\n",
    "for i in range(0, a, step):\n",
    "\n",
    "\n",
    "    #for j in range(i, i + step):\n",
    "        batch_x.append(X_train[i:i + step])\n",
    "        batch_y.append(y_train[i:i + step])\n",
    "\n",
    "all_data.append([batch_x, X_test, batch_y, y_test,header])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#house\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/house_att.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row])\n",
    "        \n",
    "with open(\"DataSets/house_price.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        y_training.append(float(row[0]))\n",
    "\n",
    "        \n",
    "print(len(X_training))\n",
    "print(len(y_training))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "#all_data.append([X_train, X_test, y_train, y_test,header])\n",
    "\n",
    "\n",
    "\n",
    "batch_x = []\n",
    "batch_y = []\n",
    "\n",
    "a = len(X_train)\n",
    "step = 1000\n",
    "\n",
    "for i in range(0, a, step):\n",
    "\n",
    "\n",
    "    #for j in range(i, i + step):\n",
    "        batch_x.append(X_train[i:i + step])\n",
    "        batch_y.append(y_train[i:i + step])\n",
    "print(len(batch_x))\n",
    "all_data.append([batch_x, X_test, batch_y, y_test,header])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort dataset by an attribute.(increasing order)\n",
    "def sort_f(X,y,column):\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        temp = i\n",
    "        for j in range(i,len(X)):\n",
    "            \n",
    "            #print(X[j])\n",
    "            #print(X[temp][column])\n",
    "            if(X[j][column]<X[temp][column]):\n",
    "                temp = j\n",
    "        if(temp != i):\n",
    "            tmp = X[i]\n",
    "            X[i] = X[temp]\n",
    "            X[temp] = tmp\n",
    "\n",
    "            tmp = y[i]\n",
    "            y[i] = y[temp]\n",
    "            y[temp] = tmp\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self,X,feature_names,labels):\n",
    "        \n",
    "        self.X = X\n",
    "        self.num_of_nodes = 0\n",
    "        self.currentsplit = 0\n",
    "        self.split_result = 0\n",
    "        self.feature_names = feature_names #coloum names\n",
    "        self.labels = labels#y\n",
    "        self.catagories = set(labels)\n",
    "        self.nodes = []\n",
    "        self.split = 0\n",
    "        self.leaf = 0\n",
    "        self.steps = [0,0,0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,labels,X,feature_ids):\n",
    "        \n",
    "        self.split_result = 0\n",
    "        self.split = 0 #which column / which feature id\n",
    "        self.feature_ids = feature_ids\n",
    "        self.labels = labels\n",
    "        self.X = X\n",
    "        self.nodes = []\n",
    "        self.regr = 0\n",
    "        self.depth = 0\n",
    "        self.top = 0\n",
    "        self.bottom = 0\n",
    "        self.steps = [0,0,0]\n",
    "        self.prev_node = 0\n",
    "        \n",
    "        self.leaf = 0 #true or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X,labels,column,bottom,top):#return splited data\n",
    "    \n",
    "\n",
    "    #Return a portion of the dataset, which's attributes is in a certain\n",
    "    \n",
    "    sub_label = [labels[x] for x in range(len(labels)) if X[x][column]<top and X[x][column]>=bottom]\n",
    "    sub_X = [X[x] for x in range(len(X)) if X[x][column]<top and X[x][column]>=bottom]\n",
    "\n",
    "\n",
    "        \n",
    "    return [sub_X,sub_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(regr_type,X,y,column,dgr):\n",
    "    \n",
    "    X = [ [X[i][column]] for i in range(len(X)) ]\n",
    "\n",
    "    \n",
    "    regr = LinearRegression()\n",
    "    regr.fit(X,y)\n",
    "    \n",
    "    \n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(regr,X,y,column,regr_type,dgr):\n",
    "    \n",
    "    \n",
    "\n",
    "    X = [ [X[i][column]] for i in range(len(X)) ]\n",
    "    if(regr_type == 1):\n",
    "        X = PolynomialFeatures(degree=dgr).fit_transform(X)\n",
    "    predict = regr.predict(X)\n",
    "\n",
    "    difference = []\n",
    "    \n",
    "    for i in range(len(predict)):\n",
    "        difference.append( (predict[i]-y[i])**2 )\n",
    "    error = sum(difference)/len(difference)\n",
    "\n",
    "  \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(i,j,column):\n",
    "    \n",
    "    \n",
    " \n",
    "    n1 = [ i[0][k][column] for k in range(len(i[0])) ]\n",
    "    n2 = [ j[0][k][column] for k in range(len(j[0])) ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    Ni = len(n1)\n",
    "    Nj = len(n2)\n",
    "    \n",
    "    s1i = sum(n1)/Ni\n",
    "    s1j = sum(n2)/Nj\n",
    "    \n",
    "    s2i = sum([x**2 for x in n1])/Ni\n",
    "    s2j = sum([x**2 for x in n2])/Nj\n",
    "    \n",
    "    s3i = sum([x*y for x,y in zip(n1,i[1])])/Ni\n",
    "    s3j = sum([x*y for x,y in zip(n2,j[1])])/Nj\n",
    "    \n",
    "    s4i = sum(i[1])/Ni\n",
    "    s4j = sum(j[1])/Nj\n",
    "    \n",
    "    D = (s1i-s1j)**2 + (s2i-s2j)**2 + (s3i-s3j)**2 +(s4i-s4j)**2\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_distance(sliced_data,column):\n",
    "    \n",
    "    dist = 0\n",
    "    min_dist = -1\n",
    "    index1 = -1\n",
    "    index2 = -1\n",
    "    \n",
    "    #determine what to merge accordint to the linear regression\n",
    "    for i in range(len(sliced_data)-1):\n",
    "\n",
    "            dist = calculate_distance(sliced_data[i],sliced_data[i+1],column)\n",
    "            \n",
    "            if(min_dist == -1):\n",
    "                min_dist = dist\n",
    "                index1 = i\n",
    "                index2 = i+1\n",
    "            if(dist<min_dist):\n",
    "                min_dist = dist\n",
    "                index1 = i\n",
    "                index2 = i+1\n",
    "    \n",
    "    return index1,index2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(sliced_data,regressions,column):\n",
    "    \n",
    "   \n",
    "    index1,index2 = find_min_distance(sliced_data,column)\n",
    "    \n",
    "\n",
    "\n",
    "    sliced_data[index1][0] = sliced_data[index1][0]+sliced_data[index2][0]\n",
    "    sliced_data[index1][1] = sliced_data[index1][1]+sliced_data[index2][1]\n",
    "\n",
    "    regressions[index1] = regression(0,sliced_data[index1][0],sliced_data[index1][1],column,0)\n",
    "    \n",
    "    sliced_data.pop(index2)\n",
    "    regressions.pop(index2)\n",
    "    \n",
    "    return sliced_data,regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(X,labels,feature_ids,steps,div):\n",
    "    \n",
    "    step = -1\n",
    "    #print(steps)\n",
    "    features = 0 \n",
    "    svalue = 0\n",
    "    \n",
    "    min_error = -1\n",
    "    min_sliced_data = []\n",
    "    min_regressions = []\n",
    "    min_steps = -1\n",
    "    min_column = -1\n",
    "\n",
    "    for column in feature_ids:\n",
    "           \n",
    "            \n",
    "            X,labels = sort_f(X,labels,column)\n",
    "            features = [ X[j][column] for j in range(len(X)) ] \n",
    "            \n",
    "            sliced_data = []\n",
    "            regressions = []\n",
    "           \n",
    "            #determine the the range of the values\n",
    "            dist = abs(features[0]-features[-1])\n",
    "            \n",
    "            #defien a step size\n",
    "            step = int(dist/10)\n",
    "            \n",
    "            if(step < 2):\n",
    "                step = 1#minimum stepsize\n",
    "                #After the minimum steps size has benn reached,on an attribute,we not allow for infinite splits\n",
    "                if(steps[column] > 4):\n",
    "                    continue\n",
    "            #slice data according to step size\n",
    "            for k in range(int(features[0]),int(features[-1])+1,step): \n",
    "                \n",
    "                sliced_data.append(get_features(X,labels,column,k,k+step))\n",
    "                \n",
    "                if( len(sliced_data[-1][0]) == 0):\n",
    "                    \n",
    "                    \n",
    "                    sliced_data.pop(-1)\n",
    "                    continue\n",
    "                regressions.append( regression( 0,sliced_data[-1][0],sliced_data[-1][1],column,0 ) )\n",
    "            #merge the data\n",
    "            while(len(sliced_data)>div):\n",
    "               \n",
    "                sliced_data,regressions = merge(sliced_data,regressions,column)\n",
    "                \n",
    "            \n",
    "            error = 0\n",
    "            for i in range(len(sliced_data)):\n",
    "                \n",
    "                error += calculate_error(regressions[i],sliced_data[i][0],sliced_data[i][1],column,0,0)\n",
    "            \n",
    "            if(min_error == -1):\n",
    "                min_sliced_data = sliced_data\n",
    "                min_regressions = regressions\n",
    "                min_steps = step\n",
    "                min_column = column\n",
    "                min_error = error\n",
    "                continue\n",
    "            #choose the splited data with the minimum error\n",
    "            if(error<min_error):\n",
    "                min_sliced_data = sliced_data\n",
    "                min_regressions = regressions\n",
    "                min_steps = step\n",
    "                min_column = column\n",
    "    \n",
    "\n",
    "    if(min_steps < 2 and min_steps>=0):\n",
    "            steps[min_column] += 1\n",
    "    \n",
    "    return min_sliced_data,min_regressions,min_column,steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X,feature_ids,labels,leaf_size,limit,div,depth,steps):\n",
    "    \n",
    "    #find the best split for sub_nodes\n",
    "    #return sub_nodes\n",
    "\n",
    "    boundaries = [] \n",
    "    \n",
    "    \n",
    "    split = 0 \n",
    "    sub_nodes = []\n",
    "\n",
    "    st = steps.copy()\n",
    "    \n",
    "    #get the best split \n",
    "    split_data,split_regression,column,st = find_best_split(X,labels,feature_ids,st,div)\n",
    " \n",
    "    \n",
    "    for i,j in zip(split_data,split_regression):\n",
    "\n",
    "\n",
    "        node = Node(i[1],i[0],feature_ids)#\n",
    "        node.split = column   \n",
    "\n",
    " \n",
    "\n",
    "        node.split_result = i[0][-1][column]\n",
    "        node.depth = depth\n",
    "        node.regr = j\n",
    "\n",
    "        node.top = i[0][-1][column]\n",
    "        node.bottom = i[0][0][column]\n",
    "        node.steps = st\n",
    "\n",
    "\n",
    "        \n",
    "        if(len(node.labels) <= leaf_size or calculate_error(node.regr,node.X,node.labels,split,0,3)<limit):\n",
    "            node.leaf = 1\n",
    "\n",
    "\n",
    "        else:\n",
    "            node.leaf = 0\n",
    "        sub_nodes.append(node)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(depth == 2000):\n",
    "        for i in sub_nodes:\n",
    "            i.leaf = 1\n",
    "            print(\"leaf2\")\n",
    "        return sub_nodes\n",
    "    \n",
    "    depth +=1\n",
    "\n",
    "    \n",
    "    leaf =  0\n",
    "    for i in sub_nodes:\n",
    "\n",
    "        if(i.leaf == 1):\n",
    "            leaf +=1\n",
    "\n",
    "            \n",
    "            \n",
    "    if(leaf == len(sub_nodes) and leaf != 0):\n",
    "\n",
    "        return sub_nodes\n",
    "    \n",
    "    else:\n",
    "        for node in sub_nodes:\n",
    "            if(node.leaf == 0):\n",
    "                    node.nodes = build_tree(node.X,node.feature_ids,node.labels,leaf_size,limit,div,depth,node.steps)\n",
    "   \n",
    "\n",
    "               \n",
    "\n",
    "    return sub_nodes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rebuild_tree(X,feature_ids,labels,leaf_size,limit,div,depth,steps,prev_node):\n",
    "    \n",
    "    #Két felé bontjuk az adatokat úgy hogy a legkisseb mse kapjuk\n",
    "    #print(prev_node.depth)\n",
    "    boundaries = [] # last element of each bach\n",
    "    \n",
    "    \n",
    "    \n",
    "    split = 0 \n",
    "    sub_nodes = []\n",
    "    \n",
    "    st = steps.copy()\n",
    "    \n",
    "    \n",
    "    split_data,split_regression,column,st = find_best_split(X,labels,feature_ids,st,div)\n",
    "    \n",
    "    \n",
    "    rebuild = 0\n",
    "    err_old = 0\n",
    "    err_new = 0\n",
    "    \n",
    "    if(len(prev_node.nodes) == len(split_data)):\n",
    "            ''''print(\"///\")\n",
    "            print(div)\n",
    "            print(len(prev_node.nodes))\n",
    "            print(len(split_data))'''\n",
    "\n",
    "            \n",
    "            \n",
    "            for i in range(len(prev_node.nodes)):\n",
    "                err_old += calculate_error(prev_node.nodes[i].regr, prev_node.nodes[i].X,prev_node.nodes[i].labels,\n",
    "                                                prev_node.nodes[i].split,0,3)\n",
    "                \n",
    "                err_new += calculate_error(prev_node.nodes[i].regr, split_data[i][0], split_data[i][1],\n",
    "                                                column, 0, 3)\n",
    "\n",
    "            \n",
    "            for i in range(len(split_data)):\n",
    "                err_new += calculate_error(split_regression[i], split_data[i][0], split_data[i][1],\n",
    "                                                column, 0, 3)\n",
    "                err_old += calculate_error(prev_node.nodes[i].regr, split_data[i][0], split_data[i][1],\n",
    "                                                    column, 0, 3)\n",
    "    \n",
    "    else:\n",
    "        #print(\"in2\")\n",
    "        #print(len(prev_node.nodes))\n",
    "        #print(len(split_data))\n",
    "        for i in range(len(prev_node.nodes)):\n",
    "            err_old += calculate_error(prev_node.nodes[i].regr, prev_node.nodes[i].X,prev_node.nodes[i].labels,\n",
    "                                            prev_node.nodes[i].split,0,3)\n",
    "\n",
    "\n",
    "        for i in range(len(split_data)):\n",
    "            err_new += calculate_error(split_regression[i], split_data[i][0], split_data[i][1],\n",
    "                                            column, 0, 3)\n",
    "\n",
    "        #print(err_old)\n",
    "        #print(err_new)\n",
    "    \n",
    "    #diff = err_new/err_old\n",
    "    min_err = min(err_new,err_old)\n",
    "    #print(diff)\n",
    "\n",
    "    if(err_new<err_old):\n",
    "        rebuild = 1\n",
    "        #rebuild\n",
    "    \n",
    "    c = 0\n",
    "    if(rebuild == 0):\n",
    "        if(len(prev_node.nodes) == len(split_data)):\n",
    "            for node in prev_node.nodes:\n",
    "                    if(node.leaf == 0):\n",
    "                        #node.nodes = rebuild_tree(node.X,node.feature_ids,node.labels,leaf_size,limit,div,depth,node.steps,node)\n",
    "                        node.nodes = rebuild_tree(split_data[c][0],node.feature_ids,split_data[c][1],leaf_size,limit,div,depth,node.steps,node)\n",
    "                        c+=1\n",
    "                \n",
    "    else:\n",
    "        if(len(prev_node.nodes) == len(split_data)):\n",
    "            a=0\n",
    "            for node in prev_node.nodes:\n",
    "                #megváltoztatni az értékeket\n",
    "                    node.X = split_data[a][0]\n",
    "                    node.labels = split_data[a][1]\n",
    "                    if(node.leaf == 0):\n",
    "                        #print(\"build\")\n",
    "                        node.nodes = build_tree(split_data[a][0],prev_node.feature_ids,split_data[a][1],leaf_size,limit,div,prev_node.depth,prev_node.steps)\n",
    "                        a+=1\n",
    "    return prev_node.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicialize(X,feature_names,labels,leaf_size,limit,div,depth,prev_nodes,rebuild):\n",
    "    \n",
    "\n",
    "    feature_ids = [x for x in range(len(feature_names))]\n",
    "    tree = Tree(X,feature_names,labels)\n",
    "    steps = []\n",
    "    for i in feature_ids:\n",
    "        steps.append(0)\n",
    "\n",
    "    if(rebuild == 1):\n",
    "        \n",
    "        for i in prev_nodes.nodes:\n",
    "            i.nodes = rebuild_tree(X,feature_ids,labels,leaf_size,limit,div,depth,steps,i)\n",
    "        tree.nodes = prev_nodes.nodes\n",
    "        \n",
    "    else:\n",
    "        tree.nodes = build_tree(X,feature_ids,labels,leaf_size,limit,div,depth,steps)\n",
    "   \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "7.274607181549072\n",
      "-------------------------------------------------------\n",
      "9.715100049972534\n",
      "-------------------------------------------------------\n",
      "13.536314487457275\n",
      "-------------------------------------------------------\n",
      "17.22182321548462\n",
      "-------------------------------------------------------\n",
      "0.18744921684265137\n",
      "-------------------------------------------------------\n",
      "0.17282700538635254\n",
      "-------------------------------------------------------\n",
      "0.1550900936126709\n",
      "-------------------------------------------------------\n",
      "0.15621256828308105\n",
      "-------------------------------------------------------\n",
      "15.033483028411865\n",
      "-------------------------------------------------------\n",
      "8.379863023757935\n",
      "-------------------------------------------------------\n",
      "16.59626841545105\n",
      "-------------------------------------------------------\n",
      "14.667150259017944\n",
      "-------------------------------------------------------\n",
      "55.17942833900452\n",
      "-------------------------------------------------------\n",
      "37.78995871543884\n",
      "-------------------------------------------------------\n",
      "24.338786840438843\n",
      "-------------------------------------------------------\n",
      "27.509931564331055\n"
     ]
    }
   ],
   "source": [
    "forest = []\n",
    "times = []\n",
    "divide = [2,3,4,5]\n",
    "\n",
    "\n",
    "\n",
    "for i in all_data:\n",
    "    f = []\n",
    "    t = []\n",
    "    for k in divide:\n",
    "            print(\"-------------------------------------------------------\")\n",
    "\n",
    "            start = time.time()\n",
    "            tree = inicialize(i[0][0],i[-1],i[2][0],10,1,k,1,0,0)\n",
    "            #print(tree)\n",
    "            for u,v in zip(i[0][1:],i[2][1:]): \n",
    "                #print(\"....................................................\")\n",
    "                tree = inicialize(u,i[-1],v,10,1,k,1,tree,1)\n",
    "\n",
    "            end = time.time()\n",
    "            \n",
    "            f.append(tree)\n",
    "            print(end-start)\n",
    "            t.append(end-start)\n",
    "            \n",
    "            \n",
    "    forest.append(f)\n",
    "    times.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(node,value):\n",
    "\n",
    "    if(node.leaf == 1 ):#\n",
    "        p = node.regr.predict(np.array(value[node.split]).reshape((1,-1)))\n",
    "\n",
    "        \n",
    "        return p\n",
    "    else:\n",
    "\n",
    "        c=0\n",
    "        for i in node.nodes:\n",
    "           \n",
    "            if (i.top>=value[i.split] and i.bottom<=value[i.split]):\n",
    "               \n",
    "                c+=1\n",
    "                p=predict(i,value)\n",
    "                return p\n",
    "        if(c == 0):\n",
    "            try:\n",
    "                p = node.regr.predict(np.array(value[node.split]).reshape((1,-1)))\n",
    "                return p\n",
    "            except:\n",
    "                return [-1]\n",
    "            \n",
    "            print(node.split)\n",
    "            print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.217730913388405, 0.20257087971928137, 0.20257087971928137, 0.20550548017015546]\n",
      "[0.04469110109068486, 0.04469110109068486, 0.04469110109068486, 0.04469110109068486]\n",
      "[0.6393409948027735, 0.7748797117667803, 0.7686060745683242, 0.7966654618348935]\n",
      "[2086.936724493143, 2549.2375402501443, 95.19048075098232, 109.8378085470439]\n",
      "[array([671.04354151]), array([588.92890171]), array([588.92890171]), array([583.12538034]), array([3.13978495]), array([3.13978495]), array([3.13978495]), array([3.13978495]), array([618.31206925]), array([645.21392312]), array([640.6297795]), array([655.34775799]), array([49159.73210555]), array([30770.73954269]), array([13297.57182327]), array([14422.87024009])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predicted_value = []#predicted points\n",
    "difference = []\n",
    "MSE = []\n",
    "sum_y = []\n",
    "\n",
    "#all_difference = []\n",
    "\n",
    "#for each tree we calculate the mean squared error\n",
    "#all_data = [X_train,X_test,y_train,y_test,header]\n",
    "all_mse = []\n",
    "      \n",
    "for v in range(len(forest)):\n",
    "    MSE = []\n",
    "    \n",
    "    for i in forest[v]:\n",
    "        \n",
    "        j = all_data[v]\n",
    "        \n",
    "        X_test = j[1]\n",
    "        y_test = j[3]\n",
    "        pv = []\n",
    "        error = 0\n",
    "        mse = 0\n",
    "        for k in range(len(X_test)): \n",
    "            \n",
    "            p = predict(i,X_test[k])\n",
    "\n",
    "            if(p == None):\n",
    "                pv.append(0)\n",
    "                continue\n",
    "           \n",
    "            if(abs(y_test[k]-p[0])<1000 and p[0]>0):\n",
    "                error += abs(y_test[k]-p)\n",
    "                mse += (y_test[k]-p)**2\n",
    "                pv.append(p)\n",
    "            else:\n",
    "                #print(\"afa\")\n",
    "                pv.append(0)\n",
    "\n",
    "\n",
    "        sum_y.append(sum(y_test))\n",
    "        predicted_value.append(pv)\n",
    "        difference.append(error)\n",
    "        \n",
    "        MSE.append(mse[0]/len(X_test))\n",
    "    print(MSE)\n",
    "    all_mse.append(MSE)\n",
    "    \n",
    "    \n",
    "print(difference)\n",
    "#print(sum_y)\n",
    "#print(all_mse)\n",
    "\n",
    "with open(\"DataSets/difference_rtni.csv\", 'a',newline='') as f:\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write a row to the csv file\n",
    "    for row in all_mse:\n",
    "        writer.writerow(row)\n",
    "        \n",
    "with open(\"DataSets/times_rtni.csv\", 'a',newline='') as f:\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write a row to the csv file\n",
    "    #print(times)\n",
    "    for row in times:\n",
    "        \n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
