{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in blob dataset\n",
    "\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/blob_att.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([ float(x) for x in row])\n",
    "        \n",
    "with open(\"DataSets/blob_label.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        y_training.append(int(row[0]))\n",
    "\n",
    "\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in iris dataset\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/iris.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row[:-1]\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row[:-1]])\n",
    "        y_training.append(row[-1])\n",
    "\n",
    "for i in range(len(y_training)):\n",
    "    if(y_training[i] == \"Setosa\"):\n",
    "        y_training[i] = 1\n",
    "    if(y_training[i] == \"Versicolor\"):\n",
    "        y_training[i] = 2\n",
    "    if(y_training[i] == \"Virginica\"):\n",
    "        y_training[i] = 3\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in wine dataset\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/winequality-white_att.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row[:-1]])\n",
    "        y_training.append(float(row[-1]))\n",
    "        #print(row)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])\n",
    "print(header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in house dataset\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/house_att.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row])\n",
    "        \n",
    "with open(\"DataSets/house_price.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        #print(row)\n",
    "        y_training.append(float(row[0]))#row[0]!!!\n",
    "\n",
    "        \n",
    "print(len(X_training))\n",
    "print(len(y_training))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort dataset by an attribute.(increasing order)\n",
    "def sort_f(X,y,column):\n",
    "    \n",
    "\n",
    "  \n",
    "    sortf = zip(X,y)\n",
    "    sortf= sorted(sortf,key = lambda x:x[0][column])\n",
    "    X = [x for x,y in sortf]\n",
    "    y = [y for x,y in sortf]\n",
    "    \n",
    "    \n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort dataset by an attribute.(increasing order)\n",
    "def sort_f2(X,y,column):\n",
    "    \n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    p = X[:,column].argsort()\n",
    "    X = X[p]\n",
    "    y = y[p]\n",
    "\n",
    "    return X.tolist(),y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self,X,feature_names,labels):\n",
    "        \n",
    "        self.X = X\n",
    "        self.num_of_nodes = 0\n",
    "        self.currentsplit = 0\n",
    "        self.split_result = 0\n",
    "        self.feature_names = feature_names #coloum names\n",
    "        self.labels = labels#y\n",
    "        self.catagories = set(labels)\n",
    "        self.nodes = []\n",
    "        self.leaf = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,labels,X,feature_ids):\n",
    "        \n",
    "        self.split_result = 0\n",
    "        self.split = 0 #which column / which feature id\n",
    "        self.feature_ids = feature_ids\n",
    "        self.labels = labels\n",
    "        self.X = X\n",
    "        self.nodes = []\n",
    "        self.regr = 0\n",
    "        self.depth = 0\n",
    "        \n",
    "        self.leaf = 0 #true or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X,labels,column,split_value):\n",
    "    \n",
    "    #Split the dataset into two parts\n",
    "    #The first part has values  lower than split_value\n",
    "    #The second part has values  bigger or equal than split_value\n",
    "    \n",
    "    features = [ X[i][column] for i in range(len(X)) ]\n",
    "    \n",
    "    sub_labels = []\n",
    "    \n",
    "    sub_label1 = []\n",
    "    sub_label2 = []\n",
    "    sub_x1 = []\n",
    "    sub_x2 = []\n",
    "    \n",
    "    for x in range(len(features)):\n",
    "        if(features[x]<split_value):\n",
    "            sub_label1.append(labels[x])\n",
    "            sub_x1.append(X[x])\n",
    "        else:\n",
    "            sub_label2.append(labels[x])\n",
    "            sub_x2.append(X[x])\n",
    "    \n",
    "    sub_labels.append([sub_label1,sub_x1,column])\n",
    "    sub_labels.append([sub_label2,sub_x2,column])\n",
    "\n",
    "    \n",
    "    #return splited data,containing the labels,features and the the column    \n",
    "    return sub_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(regr_type,X,y,column):\n",
    "    \n",
    "    #calculate linear regression\n",
    "    \n",
    "    X = [ [X[i][column]] for i in range(len(X)) ]\n",
    "    \n",
    "    regr = LinearRegression()\n",
    "    regr.fit(X,y)\n",
    "    \n",
    "    \n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(regr,X,y,column):\n",
    "    \n",
    "    \n",
    "    X = [ [X[i][column]] for i in range(len(X)) ]\n",
    "    predict = regr.predict(X)\n",
    "    \n",
    "    difference = []\n",
    "    \n",
    "    for i in range(len(predict)):\n",
    "        difference.append( (predict[i]-y[i])**2 )\n",
    "    error = sum(difference)/len(difference)\n",
    "\n",
    "  \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_split_regression(X,labels,column,split_value):\n",
    "    \n",
    "    error = 0\n",
    "    \n",
    "    sub_labels = get_features(X,labels,column,split_value) \n",
    "    \n",
    "    for i in sub_labels:\n",
    "\n",
    "        if(len(i[0]) == 0):\n",
    "            return -1\n",
    "        #calculate linear regression for each part of the splited data\n",
    "        regr = regression(1,i[1],i[0],column)\n",
    "        #calculate the rror of linear regression\n",
    "        error+= calculate_error(regr,i[1],i[0],column)\n",
    "\n",
    "  \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(X,labels,feature_ids):\n",
    "    \n",
    "    #for each column we try to find the best split_value\n",
    "    #we return the split_value wich results in the lowest standard deviation\n",
    "    \n",
    "    lowest_error = -1\n",
    "    split = 0\n",
    "    split_value = 0\n",
    "    V = 0 \n",
    "    \n",
    "    features = 0 \n",
    "    svalue = 0\n",
    "\n",
    "    for i in feature_ids:\n",
    "        \n",
    "            #sort\n",
    "            X,labels = sort_f(X,labels,i)\n",
    "            features = [ X[j][i] for j in range(len(X)) ] \n",
    "            \n",
    "\n",
    "            #iterate through features, take two values avarage, calculate standard deviation after split\n",
    "            for k in range(0,len(features)-1,2): \n",
    "\n",
    "                if(features[k]==features[k+1]):\n",
    "                    continue\n",
    "                \n",
    "                svalue = (features[k]+features[k+1])/2\n",
    "                V = calculate_split_regression(X,labels,i,svalue)\n",
    "                \n",
    "                if(lowest_error == -1):\n",
    "                    lowest_error = V\n",
    "                    split_value = svalue\n",
    "                    split = i\n",
    "                \n",
    "                #after the split, if the standard deviation is lower than in a previous split, we choose this one\n",
    "                if(V<lowest_error and V != -1):\n",
    "\n",
    "                    split_value = svalue\n",
    "                    lowest_error = V\n",
    "                    split = i\n",
    "\n",
    "    \n",
    "    return split,split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X,feature_ids,labels,leaf_size,limit,depth):\n",
    "    \n",
    "    #find the best split for sub_nodes\n",
    "\n",
    "    split = 0 \n",
    "    sub_nodes = []\n",
    "    \n",
    "    #get the best split value and column\n",
    "    split,split_value = find_best_split(X,labels,feature_ids)\n",
    "\n",
    "    node_labels = get_features(X,labels,split,split_value)  \n",
    "\n",
    "    \n",
    "    #create objects and inicialize them\n",
    "    for i in node_labels:\n",
    "        if(len(i[0]) == 0):\n",
    "            continue\n",
    "        node = Node(i[0],i[1],feature_ids)\n",
    "        node.split = split\n",
    "        node.split_result = split_value\n",
    "        node.depth = depth\n",
    "\n",
    "        node.regr = regression(1,i[1],i[0],split)\n",
    "        \n",
    "        \n",
    "\n",
    "        if(len(node.labels) <= leaf_size or calculate_error(node.regr,node.X,node.labels,split)<limit):\n",
    "            node.leaf = 1\n",
    "\n",
    "            \n",
    "        else:\n",
    "            node.leaf = 0\n",
    "        sub_nodes.append(node)\n",
    "    \n",
    "\n",
    "    if(depth == 3000):\n",
    "        for i in sub_nodes:\n",
    "            i.leaf = 1\n",
    "        return sub_nodes\n",
    "    \n",
    "    depth +=1\n",
    "    \n",
    "    leaf =  0\n",
    "    for i in sub_nodes:\n",
    "        if(i.leaf == 1):\n",
    "            leaf +=1\n",
    "    if(leaf == len(sub_nodes)):\n",
    "   \n",
    "        return sub_nodes\n",
    "    \n",
    "    else:\n",
    "        for node in sub_nodes:\n",
    "\n",
    "            if(node.leaf == 0):\n",
    "                \n",
    "                node.nodes = build_tree(node.X,node.feature_ids,node.labels,leaf_size,limit,depth)#node.depth\n",
    "\n",
    "\n",
    "    return sub_nodes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicialize(X,feature_names,labels,leaf_size,limit,div):\n",
    "    \n",
    "    depth = 1\n",
    "    feature_ids = [x for x in range(len(feature_names))]\n",
    "    tree = Tree(X,feature_names,labels)\n",
    "    #start building tree\n",
    "    tree.nodes = build_tree(X,feature_ids,labels,leaf_size,limit,depth)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129.25556015968323\n",
      "-------------------------------------------------------\n",
      "0.02221989631652832\n",
      "-------------------------------------------------------\n",
      "3.78776478767395\n",
      "-------------------------------------------------------\n",
      "134.10051584243774\n"
     ]
    }
   ],
   "source": [
    "forest = []\n",
    "times = []\n",
    "#limits = [0.5,0.75,1,1.25,1.5,1.75,2]\n",
    "#divide = [2]\n",
    "size = 20\n",
    "counter = 0\n",
    "var = 0\n",
    "#for each dataset we build a tree and mesure the elapsed time\n",
    "for i in all_data: \n",
    "    f = []\n",
    "    t = []\n",
    "    print(\"-------------------------------------------------------\")\n",
    "\n",
    "    if(counter == 0):\n",
    "        size =20\n",
    "        var = 0.5\n",
    "    if(counter == 1):\n",
    "        size =10\n",
    "        var = 0.2\n",
    "    if(counter == 2):\n",
    "        size =20\n",
    "        var = 0.8\n",
    "    if(counter == 3):\n",
    "        size = 20\n",
    "        var = 1\n",
    "\n",
    "    start = time.time()\n",
    "    tree = inicialize(i[0],i[-1],i[2],size,var,1)\n",
    "    end = time.time()\n",
    "    f.append(tree)\n",
    "    t.append(end-start)\n",
    "    counter+=1\n",
    "    print(end-start)\n",
    "\n",
    "    forest.append(f)\n",
    "    times.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(node,value):\n",
    "\n",
    "    if(node.leaf == 1):\n",
    "        p = node.regr.predict(np.array(value[node.split]).reshape((1,-1)) )\n",
    "        \n",
    "        return p\n",
    "    else:\n",
    "        if (node.nodes[0].split_result<value[node.nodes[0].split]):\n",
    "            \n",
    "            p=predict(node.nodes[1],value)\n",
    "            return p\n",
    "        else:\n",
    "            p=predict(node.nodes[0],value)\n",
    "            return p\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([715.81314213]), array([3.92454552]), array([604.73511686]), array([9314.43601119])]\n",
      "[4053, 58, 5793.0, 628285.3781633918]\n",
      "[array([0.28037413]), array([0.03160336]), array([0.62034028]), array([44.05206218])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predicted_value = []#predicted points\n",
    "difference = []\n",
    "MSE = []\n",
    "sum_y = []\n",
    "\n",
    "\n",
    "all_mse = []\n",
    "\n",
    "#for each tree we calculate the mean squared error\n",
    "#all_data = [X_train,X_test,y_train,y_test,header]\n",
    "\n",
    "for v in range(len(forest)):\n",
    "    MSE = []\n",
    "    for i in forest[v]:\n",
    "        j = all_data[v]\n",
    "        \n",
    "        X_test = j[1]\n",
    "        y_test = j[3]\n",
    "        pv = []\n",
    "        error = 0\n",
    "        mse = 0\n",
    "        for k in range(len(X_test)): \n",
    "\n",
    "            p = predict(i,X_test[k])\n",
    "            #print(p,y_test[k])\n",
    "           \n",
    "\n",
    "            error += abs(y_test[k]-p)\n",
    "            mse += (y_test[k]-p)**2\n",
    "            pv.append(p)\n",
    "            \n",
    "\n",
    "        sum_y.append(sum(y_test))\n",
    "        predicted_value.append(pv)\n",
    "        difference.append(error)\n",
    "        mse = mse/len(X_test)\n",
    "\n",
    "    all_mse.append(mse)\n",
    "    \n",
    "    \n",
    "print(difference)\n",
    "print(sum_y)\n",
    "\n",
    "print(all_mse)\n",
    "\n",
    "\n",
    "with open(\"Results/difference_rtl.csv\", 'a',newline='') as f:\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write a row to the csv file\n",
    "    for row in all_mse:\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open(\"Results/times_rtl.csv\", 'a',newline='') as f:\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write a row to the csv file\n",
    "    for row in times:\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
