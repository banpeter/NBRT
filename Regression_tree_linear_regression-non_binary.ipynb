{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in blob dataset\n",
    "\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/blob_att.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([ float(x) for x in row])\n",
    "        \n",
    "with open(\"DataSets/blob_label.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        y_training.append(int(row[0]))\n",
    "\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in iris dataset\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/iris.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row[:-1]\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row[:-1]])\n",
    "        y_training.append(row[-1])\n",
    "\n",
    "for i in range(len(y_training)):\n",
    "    if(y_training[i] == \"Setosa\"):\n",
    "        y_training[i] = 1\n",
    "    if(y_training[i] == \"Versicolor\"):\n",
    "        y_training[i] = 2\n",
    "    if(y_training[i] == \"Virginica\"):\n",
    "        y_training[i] = 3\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in wine dataset\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/winequality-white_att.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row[:-1]])\n",
    "        y_training.append(float(row[-1]))\n",
    "        #print(row)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# read in house dataset\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/house_att.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row])\n",
    "        \n",
    "with open(\"DataSets/house_price.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        y_training.append(float(row[0]))\n",
    "\n",
    "        \n",
    "print(len(X_training))\n",
    "print(len(y_training))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort dataset by an attribute.(increasing order)\n",
    "def sort_f(X,y,column):\n",
    "    \n",
    "\n",
    "  \n",
    "    sortf = zip(X,y)\n",
    "    sortf= sorted(sortf,key = lambda x:x[0][column])\n",
    "    X = [x for x,y in sortf]\n",
    "    y = [y for x,y in sortf]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self,X,feature_names,labels):\n",
    "        \n",
    "        self.X = X\n",
    "        self.num_of_nodes = 0\n",
    "        self.currentsplit = 0\n",
    "        self.split_result = 0\n",
    "        self.feature_names = feature_names #coloum names\n",
    "        self.labels = labels#y\n",
    "        self.catagories = set(labels)\n",
    "        self.nodes = []\n",
    "        self.split = 0\n",
    "        self.leaf = 0\n",
    "        self.steps = [0,0,0]\n",
    "        self.std = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,labels,X,feature_ids):\n",
    "        \n",
    "        self.split_result = 0\n",
    "        self.split = 0 #which column / which feature id\n",
    "        self.feature_ids = feature_ids\n",
    "        self.labels = labels\n",
    "        self.X = X\n",
    "        self.nodes = []\n",
    "        self.regr = 0\n",
    "        self.depth = 0\n",
    "        self.top = 0\n",
    "        self.bottom = 0\n",
    "        self.steps = [0,0,0]\n",
    "        self.std = []\n",
    "        self.leaf = 0 #true or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X,labels,column,bottom,top):#return splited data\n",
    "    \n",
    "    #Return a portion of the dataset, which's attributes is in a certain\n",
    "\n",
    "    sub_label = [labels[x] for x in range(len(labels)) if X[x][column]<top and X[x][column]>=bottom]\n",
    "    sub_X = [X[x] for x in range(len(X)) if X[x][column]<top and X[x][column]>=bottom]\n",
    "\n",
    "        \n",
    "    return [sub_X,sub_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(regr_type,X,y,column,dgr):\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    X = [ [X[i][column]] for i in range(len(X)) ]\n",
    "\n",
    "    \n",
    "    regr = LinearRegression()\n",
    "    regr.fit(X,y)\n",
    "    \n",
    "    \n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(regr,X,y,column,regr_type,dgr):\n",
    "    \n",
    "    \n",
    "    \n",
    "    X = [ [X[i][column]] for i in range(len(X)) ]\n",
    "    if(regr_type == 1):\n",
    "        X = PolynomialFeatures(degree=dgr).fit_transform(X)\n",
    "    predict = regr.predict(X)\n",
    "\n",
    "    difference = []\n",
    "    \n",
    "    for i in range(len(predict)):\n",
    "        difference.append( (predict[i]-y[i])**2 )\n",
    "    error = sum(difference)/len(difference)\n",
    "\n",
    "  \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(i,j,column):\n",
    "    \n",
    "    \n",
    " \n",
    "    n1 = [ i[0][k][column] for k in range(len(i[0])) ]\n",
    "    n2 = [ j[0][k][column] for k in range(len(j[0])) ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    Ni = len(n1)\n",
    "    Nj = len(n2)\n",
    "    \n",
    "    s1i = sum(n1)/Ni\n",
    "    s1j = sum(n2)/Nj\n",
    "    \n",
    "    s2i = sum([x**2 for x in n1])/Ni\n",
    "    s2j = sum([x**2 for x in n2])/Nj\n",
    "    \n",
    "    s3i = sum([x*y for x,y in zip(n1,i[1])])/Ni\n",
    "    s3j = sum([x*y for x,y in zip(n2,j[1])])/Nj\n",
    "    \n",
    "    s4i = sum(i[1])/Ni\n",
    "    s4j = sum(j[1])/Nj\n",
    "    \n",
    "    D = (s1i-s1j)**2 + (s2i-s2j)**2 + (s3i-s3j)**2 +(s4i-s4j)**2\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_distance(sliced_data,column):\n",
    "    \n",
    "    dist = 0\n",
    "    min_dist = -1\n",
    "    index1 = -1\n",
    "    index2 = -1\n",
    "    \n",
    "    \n",
    "    for i in range(len(sliced_data)-1):\n",
    "\n",
    "            dist = calculate_distance(sliced_data[i],sliced_data[i+1],column)\n",
    "            \n",
    "            if(min_dist == -1):\n",
    "                min_dist = dist\n",
    "                index1 = i\n",
    "                index2 = i+1\n",
    "            if(dist<min_dist):\n",
    "                min_dist = dist\n",
    "                index1 = i\n",
    "                index2 = i+1\n",
    "    \n",
    "    return index1,index2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(sliced_data,regressions,column):\n",
    "    \n",
    "   \n",
    "\n",
    "    index1,index2 = find_min_distance(sliced_data,column)\n",
    "    \n",
    "\n",
    "    sliced_data[index1][0] = sliced_data[index1][0]+sliced_data[index2][0]\n",
    "    sliced_data[index1][1] = sliced_data[index1][1]+sliced_data[index2][1]\n",
    "\n",
    "    regressions[index1] = regression(0,sliced_data[index1][0],sliced_data[index1][1],column,0)\n",
    "    \n",
    "    sliced_data.pop(index2)\n",
    "    regressions.pop(index2)\n",
    "    \n",
    "    return sliced_data,regressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_std(data):\n",
    "    \n",
    "    #print(data)\n",
    "    mean = sum(data)/len(data)\n",
    "    \n",
    "    variance = 0\n",
    "    \n",
    "    for i in data:\n",
    "        variance += (i-mean)**2\n",
    "    \n",
    "    \n",
    "    return math.sqrt(variance/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dist2(data1,data2):\n",
    "\n",
    "    #print(data1)\n",
    "    #print(data2)\n",
    "    d1 = sum(data1)/len(data1)\n",
    "    d2 = sum(data2)/len(data2)\n",
    "    return abs(d2-d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dist(data1,data2):#euclidean\n",
    "\n",
    "    #print(data1)\n",
    "    #print(data2)\n",
    "    d1 = sum(data1)/len(data1)\n",
    "    d2 = sum(data2)/len(data2)\n",
    "    return math.sqrt((d2-d1)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_merge(sliced_data,index,std,column):\n",
    "    \n",
    "   \n",
    "\n",
    "    #index1,index2 = find_min_distance(sliced_data,column)\n",
    "    std_local = 0\n",
    "\n",
    "    for i in range(len(sliced_data[0][0][0])):\n",
    "\n",
    "        X = sliced_data[index][0]\n",
    "        X2 = sliced_data[index+1][0]\n",
    "        features = [ X[j][i] for j in range(len(X)) ] + [ X2[j][i] for j in range(len(X2)) ]\n",
    "        #std_local += calculate_std(features)\n",
    "        std_local += calculate_dist([ X[j][i] for j in range(len(X)) ],[ X2[j][i] for j in range(len(X2)) ])\n",
    "\n",
    "\n",
    "\n",
    "    if(std_local <= std ) :\n",
    "\n",
    "        sliced_data[index][0] = sliced_data[index][0]+sliced_data[index+1][0]\n",
    "        sliced_data[index][1] = sliced_data[index][1]+sliced_data[index+1][1]\n",
    "        sliced_data.pop(index+1)\n",
    "        return sliced_data\n",
    "   \n",
    "    return sliced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features2(sliced_data,column):\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for i in sliced_data:\n",
    "        features.append([ i[0][j][column] for j in range(len(i[0])) ])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_std_avg(features):# átadni az x vectortSzoft\n",
    "        std = 0\n",
    "\n",
    "\n",
    "        for i in range(len(features)-1):\n",
    "\n",
    "            std += calculate_dist(features[i],features[i+1])\n",
    "\n",
    "        std = std/len(features)\n",
    "\n",
    "        return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X,labels,column):# Az std valójában distance\n",
    "\n",
    "    sliced_data = [[ [x] , [y] ] for x,y in zip(X,labels)]\n",
    "\n",
    "\n",
    "\n",
    "    features = [ [X[j][column]] for j in range(len(X)) ] \n",
    "    labels = [ [j] for j in labels ] \n",
    "\n",
    "\n",
    "    std = 0\n",
    "\n",
    "    for i in range(len(sliced_data[0][0][0])):\n",
    "        std += calculate_std_avg(get_features2(sliced_data,i))\n",
    "\n",
    "    index = -1\n",
    "    l = 0\n",
    "\n",
    "    while(len(sliced_data)>=100):\n",
    "\n",
    "        index += 1\n",
    "        if(index>=len(sliced_data)-1):\n",
    "            index = 0\n",
    "            if(len(sliced_data) == l):\n",
    "                break\n",
    "            else:\n",
    "                l = len(sliced_data)\n",
    "            std = 0\n",
    "            for i in range(len(sliced_data[0][0][0])):\n",
    "                std += calculate_std_avg(get_features2(sliced_data,i))#\n",
    "            \n",
    "            \n",
    "\n",
    "        sliced_data = pre_merge(sliced_data,index,std,column)\n",
    "        \n",
    "\n",
    "    return sliced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(X,labels,feature_ids,steps,div):\n",
    "    \n",
    "    step = -1\n",
    "\n",
    "    features = 0 \n",
    "    svalue = 0\n",
    "    \n",
    "    min_error = -1\n",
    "    min_sliced_data = []\n",
    "    min_regressions = []\n",
    "    min_steps = -1\n",
    "    min_column = -1\n",
    "\n",
    "    for column in feature_ids:\n",
    "\n",
    "            \n",
    "            X,labels = sort_f(X,labels,column)\n",
    "            features = [ X[j][column] for j in range(len(X)) ] \n",
    "            \n",
    "            sliced_data = []\n",
    "            regressions = []\n",
    "            \n",
    "            #determine the the range of the values\n",
    "            dist = abs(features[0]-features[-1])\n",
    "            \n",
    "            #defien a step size\n",
    "            step = int(dist/10)\n",
    "            if(steps[column] > 11 ):\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            sliced_data = preprocess(X,labels,column)\n",
    "\n",
    "            for i in sliced_data:\n",
    "\n",
    "                regressions.append( regression( 0,i[0],i[1],column,0 ) )\n",
    "\n",
    "            #merge the data\n",
    "        \n",
    "            while(len(sliced_data)>div):\n",
    "\n",
    "                sliced_data,regressions = merge(sliced_data,regressions,column)\n",
    "\n",
    "                \n",
    "            \n",
    "            error = 0\n",
    "            for i in range(len(sliced_data)):\n",
    "                \n",
    "                error += calculate_error(regressions[i],sliced_data[i][0],sliced_data[i][1],column,0,0)\n",
    "            #sum the error after the split\n",
    "            #choose min\n",
    "            \n",
    "            if(min_error == -1):\n",
    "                min_sliced_data = sliced_data\n",
    "                min_regressions = regressions\n",
    "                min_steps = step\n",
    "                min_column = column\n",
    "                min_error = error\n",
    "                continue\n",
    "            #choose the splited data with the minimum error\n",
    "            if(error<min_error):\n",
    "                min_sliced_data = sliced_data\n",
    "                min_regressions = regressions\n",
    "                min_steps = step\n",
    "                min_column = column\n",
    "    \n",
    "    #return split,split_value\n",
    "    steps[min_column] += 1\n",
    "\n",
    "    \n",
    "    return min_sliced_data,min_regressions,min_column,steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X,feature_ids,labels,leaf_size,limit,depth,steps,div):\n",
    "       \n",
    "    #find the best split for sub_nodes\n",
    "    #return sub_nodes\n",
    "    \n",
    "    split = 0 \n",
    "    sub_nodes = []\n",
    "    \n",
    "    \n",
    "    st = steps.copy()\n",
    "    \n",
    "    #get the best split \n",
    "    split_data,split_regression,column,st = find_best_split(X,labels,feature_ids,st,div)\n",
    "    \n",
    "\n",
    "    #create objects and inicialize them\n",
    "    for i,j in zip(split_data,split_regression):\n",
    "\n",
    "        \n",
    "        node = Node(i[1],i[0],feature_ids)\n",
    "        node.split = column  \n",
    "        \n",
    "     \n",
    "       \n",
    "        node.split_result = i[0][-1][column]\n",
    "        node.depth = depth\n",
    "        node.regr = j\n",
    "        \n",
    "        node.top = i[0][-1][column]\n",
    "        node.bottom = i[0][0][column]\n",
    "        node.steps = st\n",
    "        node.std.append(calculate_error(node.regr,node.X,node.labels,split,0,3))\n",
    "        \n",
    "        \n",
    "       \n",
    "        if(len(node.labels) <= leaf_size or calculate_error(node.regr,node.X,node.labels,split,0,3)<1):\n",
    "            node.leaf = 1\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            node.leaf = 0\n",
    "        sub_nodes.append(node)\n",
    "    #print(len(sub_nodes))\n",
    "    \n",
    "\n",
    "    if(depth == 2000):\n",
    "        for i in sub_nodes:\n",
    "            i.leaf = 1\n",
    "            \n",
    "        return sub_nodes\n",
    "    \n",
    "    depth +=1\n",
    "\n",
    "    \n",
    "    leaf =  0\n",
    "    for i in sub_nodes:\n",
    "\n",
    "        if(i.leaf == 1):\n",
    "            leaf +=1\n",
    "            \n",
    "            \n",
    "    if(leaf == len(sub_nodes)):\n",
    "\n",
    "        return sub_nodes\n",
    "    \n",
    "    else:\n",
    "        for node in sub_nodes:\n",
    "\n",
    "            if(node.leaf == 0):\n",
    "                \n",
    "                node.nodes = build_tree(node.X,node.feature_ids,node.labels,leaf_size,limit,depth,node.steps,div)\n",
    "\n",
    "\n",
    "    return sub_nodes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicialize(X,feature_names,labels,leaf_size,limit,depth,div):\n",
    "    \n",
    "    \n",
    "    feature_ids = [x for x in range(len(feature_names))]\n",
    "    tree = Tree(X,feature_names,labels)\n",
    "    steps = []\n",
    "    for i in feature_ids:\n",
    "        steps.append(0)\n",
    "    #start_building\n",
    "    tree.nodes = build_tree(X,feature_ids,labels,leaf_size,limit,depth,steps,div)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5232059955596924\n",
      "-------------------------------------------------------\n",
      "1.4768362045288086\n",
      "-------------------------------------------------------\n",
      "1.4984934329986572\n",
      "-------------------------------------------------------\n",
      "1.4343822002410889\n",
      "-------------------------------------------------------\n",
      "0.31635093688964844\n",
      "-------------------------------------------------------\n",
      "0.22690629959106445\n",
      "-------------------------------------------------------\n",
      "0.23013710975646973\n",
      "-------------------------------------------------------\n",
      "0.1994631290435791\n",
      "-------------------------------------------------------\n",
      "15.92551064491272\n",
      "-------------------------------------------------------\n",
      "25.573665618896484\n",
      "-------------------------------------------------------\n",
      "30.17807412147522\n",
      "-------------------------------------------------------\n",
      "19.26021456718445\n",
      "-------------------------------------------------------\n",
      "65.32669949531555\n",
      "-------------------------------------------------------\n",
      "44.078540325164795\n",
      "-------------------------------------------------------\n",
      "33.4838981628418\n",
      "-------------------------------------------------------\n",
      "28.261881589889526\n"
     ]
    }
   ],
   "source": [
    "forest = []\n",
    "times = []\n",
    "#limits = [0.5,0.75,1,1.25,1.5,1.75,2]\n",
    "divide = [2,3,4,5]\n",
    "counter = 0\n",
    "\n",
    "#for each dataset we build a tree and mesure the elapsed time\n",
    "for i in all_data:\n",
    "    f = []\n",
    "    t = []\n",
    "    for j in divide:\n",
    "        \n",
    "        print(\"-------------------------------------------------------\")\n",
    "\n",
    "\n",
    "        if(counter == 0):\n",
    "            size =20\n",
    "            var = 0.5\n",
    "        if(counter == 1):\n",
    "            size =10\n",
    "            var = 0.2\n",
    "        if(counter == 2):\n",
    "            size =20\n",
    "            var = 0.5\n",
    "        if(counter == 3):\n",
    "            size = 20\n",
    "            var = 1\n",
    "\n",
    "        start = time.time()\n",
    "        tree = inicialize(i[0],i[-1],i[2],15,1,1,j)\n",
    "        end = time.time()\n",
    "        f.append(tree)\n",
    "        print(end-start)\n",
    "        t.append(end-start)\n",
    "        counter += 1\n",
    "    forest.append(f)\n",
    "    times.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node,value):\n",
    "\n",
    "    #steps = [5,1,0,10]\n",
    "\n",
    "    if(node.leaf == 1 ):\n",
    "\n",
    "        p =  node.regr.predict(np.array(value[node.split]).reshape((1,-1)))\n",
    "\n",
    "        X = []\n",
    "        #error = 0\n",
    "        for i in range(len(node.X[0])):\n",
    "            X.append(sum([ node.X[j][i] for j in range(len(node.X)) ]) )\n",
    "\n",
    "\n",
    "        #print(X)\n",
    "        X = [x /len(node.X) for x in X]\n",
    "        #print(X,p)\n",
    "        error = 0\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            error +=  abs(X[i]-value[i])\n",
    "            #error +=  abs(b[i]-a[i])\n",
    "        \n",
    "\n",
    "        p=[p,error]\n",
    "        #print(\"------------------------------------------------------------------------\")\n",
    "        return p\n",
    "    else:\n",
    "        \n",
    "        c=0\n",
    "        \n",
    "        p = 0\n",
    "        \n",
    "        values = []\n",
    "        for i in node.nodes:\n",
    "\n",
    "            if (i.top>=value[i.split] and i.bottom<=value[i.split]  ):\n",
    "\n",
    "                c+=1\n",
    "                \n",
    "                p = predict(i,value)\n",
    "                #values.append(p)\n",
    "                for k in p:\n",
    "                    values.append(k)\n",
    "        if(c == 0  ):\n",
    "            #print(\"_______________________________________________________________________---\")\n",
    "\n",
    "            try:\n",
    "                p =  node.regr.predict(np.array(value[node.split]).reshape((1,-1)))\n",
    "            except:\n",
    "                p = sum(node.labels)/len(node.labels)\n",
    "\n",
    "            X = []\n",
    "            #error = 0\n",
    "            for i in range(len(node.X[0])):\n",
    "                X.append(sum([ node.X[j][i] for j in range(len(node.X)) ]) )\n",
    "\n",
    "            X = [x /len(node.X) for x in X]\n",
    "    \n",
    "            error = 0\n",
    "        \n",
    "            for i in range(len(X)):\n",
    "                error +=  abs(X[i]-value[i])\n",
    "                #error +=  abs(b[i]-a[i])\n",
    "            \n",
    "            p=[p,error]\n",
    "            #return [1,10000]\n",
    "            return p\n",
    "\n",
    "\n",
    "\n",
    "            #return [1,10000]\n",
    "\n",
    "        return values\n",
    "        print('......................................................')\n",
    "        p = sum(node.labels)/len(node.labels)\n",
    "        return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5232059955596924, 1.4768362045288086, 1.4984934329986572, 1.4343822002410889], [0.31635093688964844, 0.22690629959106445, 0.23013710975646973, 0.1994631290435791], [15.92551064491272, 25.573665618896484, 30.17807412147522, 19.26021456718445], [65.32669949531555, 44.078540325164795, 33.4838981628418, 28.261881589889526]]\n",
      "[array([695.04625263]), array([618.36891397]), array([612.63679466]), array([615.7250521]), array([1.79080961]), array([1.35766423]), array([3.21617497]), array([1.82095626]), array([629.90479744]), array([709.27731135]), array([749.52348029]), array([722.84253877]), array([5756.88533565]), array([5935.60481575]), array([6052.92746591]), array([6327.2046632])]\n",
      "[4042, 4042, 4042, 4042, 57, 57, 57, 57, 5764.0, 5764.0, 5764.0, 5764.0, 616401.932560095, 616401.932560095, 616401.932560095, 616401.932560095]\n",
      "[[array([0.22936484]), array([0.21265871]), array([0.21213226]), array([0.21184664])], [array([0.03052329]), array([0.03405438]), array([0.10025547]), array([0.04210512])], [array([0.67643691]), array([0.9002939]), array([1.02705063]), array([0.94817783])], [array([14.997366]), array([15.16526664]), array([16.26483862]), array([18.81602255])]]\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(times)\n",
    "predicted_value = []#predicted points\n",
    "difference = []\n",
    "MSE = []\n",
    "sum_y = []\n",
    "\n",
    "#all_difference = []\n",
    "all_mse = []\n",
    "all_std = []\n",
    "#for each tree we calculate the mean squared error\n",
    "\n",
    "\n",
    "\n",
    "for v in range(len(forest)):\n",
    "    MSE = []\n",
    "    counter = 0\n",
    "    for i in forest[v]:\n",
    "        counter += 1\n",
    "        #print(counter)\n",
    "        j = all_data[v]\n",
    "        \n",
    "        X_test = j[1]\n",
    "        y_test = j[3]\n",
    "        pv = []\n",
    "        error = 0\n",
    "        mse = 0\n",
    "        l = 0\n",
    "       \n",
    "        for k in range(len(X_test)): \n",
    "\n",
    "            pr = predict(i,X_test[k])\n",
    "\n",
    "\n",
    "            p = 0\n",
    "            #print(p)\n",
    "            prev = 1000000000000\n",
    "            if(pr[0] != 0):\n",
    "\n",
    "                for f in range(0,len(pr)-1,2):\n",
    "                    if(pr[f+1]<prev):\n",
    "                        prev = pr[f+1]\n",
    "                        p = pr[f]\n",
    "\n",
    "\n",
    "            error += abs(y_test[k]-p)\n",
    "\n",
    "            mse += (y_test[k]-p)**2\n",
    "            pv.append(p)\n",
    "           \n",
    "\n",
    "\n",
    "        sum_y.append(sum(y_test))\n",
    "        predicted_value.append(pv)\n",
    "        difference.append(error)\n",
    "        MSE.append(mse/len(X_test))\n",
    "        #MSE.append(mse/l)\n",
    "\n",
    "    all_mse.append(MSE)\n",
    "    \n",
    "    \n",
    "print(difference)\n",
    "print(sum_y)\n",
    "\n",
    "print(all_mse)\n",
    "'''with open(\"Results/difference_rtln.csv\", 'a',newline='') as f:\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write a row to the csv file\n",
    "    for row in all_mse:\n",
    "        writer.writerow(row)\n",
    "        \n",
    "with open(\"Results/times_rtln.csv\", 'a',newline='') as f:\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write a row to the csv file\n",
    "    \n",
    "    for row in times:\n",
    "        \n",
    "        writer.writerow(row)'''\n",
    "\n",
    "print(len(predicted_value[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c8a6292cf66ce789040457b6ebf66f3ab3b90cd403744604a52a466e4391717"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
