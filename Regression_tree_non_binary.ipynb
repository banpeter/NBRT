{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "all_limits = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in blob dataset\n",
    "\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/blob_att.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([ float(x) for x in row])\n",
    "        \n",
    "with open(\"DataSets/blob_label.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        y_training.append(int(row[0]))\n",
    "\n",
    "\n",
    "threshold = []\n",
    "for i in range(len(X_training[0])):\n",
    "    vector = [x[i] for x in X_training]\n",
    "    threshold.append([min(vector),max(vector)])\n",
    "\n",
    "all_limits.append(threshold)\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in iris dataset\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/iris.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row[:-1]\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row[:-1]])\n",
    "        y_training.append(row[-1])\n",
    "\n",
    "for i in range(len(y_training)):\n",
    "    if(y_training[i] == \"Setosa\"):\n",
    "        y_training[i] = 1\n",
    "    if(y_training[i] == \"Versicolor\"):\n",
    "        y_training[i] = 2\n",
    "    if(y_training[i] == \"Virginica\"):\n",
    "        y_training[i] = 3\n",
    "\n",
    "threshold = []\n",
    "for i in range(len(X_training[0])):\n",
    "    vector = [x[i] for x in X_training]\n",
    "    threshold.append([min(vector),max(vector)])\n",
    "\n",
    "all_limits.append(threshold)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in wine dataset\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/winequality-white_att.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row[:-1]])\n",
    "        y_training.append(float(row[-1]))\n",
    "        #print(row)\n",
    "\n",
    "threshold = []\n",
    "for i in range(len(X_training[0])):\n",
    "    vector = [x[i] for x in X_training]\n",
    "    threshold.append([min(vector),max(vector)])\n",
    "\n",
    "all_limits.append(threshold)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in house price dataset\n",
    "X_training = []\n",
    "y_training = []\n",
    "header = []\n",
    "c = 0\n",
    "with open(\"DataSets/house_att.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        if(c == 0):\n",
    "            header = row\n",
    "            c+=1\n",
    "            continue\n",
    "        X_training.append([float(x) for x in row])\n",
    "        \n",
    "with open(\"DataSets/house_price.csv\",\"r\") as file:\n",
    "    r = csv.reader(file)\n",
    "    for row in r:\n",
    "        y_training.append(float(row[0]))\n",
    "\n",
    "\n",
    "threshold = []\n",
    "for i in range(len(X_training[0])):\n",
    "    vector = [x[i] for x in X_training]\n",
    "    threshold.append([min(vector),max(vector)])\n",
    "\n",
    "all_limits.append(threshold)\n",
    "        \n",
    "print(len(X_training))\n",
    "print(len(y_training))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training, test_size=0.2) # 80% training and 20% testing data\n",
    "all_data.append([X_train, X_test, y_train, y_test,header])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort dataset by an attribute.(increasing order)\n",
    "def sort_f(X,y,column):\n",
    "    \n",
    "\n",
    "  \n",
    "    sortf = zip(X,y)\n",
    "    sortf= sorted(sortf,key = lambda x:x[0][column])\n",
    "    X = [x for x,y in sortf]\n",
    "    y = [y for x,y in sortf]\n",
    "    \n",
    "    \n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self,X,feature_names,labels):\n",
    "        \n",
    "        self.X = X\n",
    "        self.num_of_nodes = 0\n",
    "        self.currentsplit = 0\n",
    "        self.split_result = 0\n",
    "        self.feature_names = feature_names #coloum names\n",
    "        self.labels = labels#y\n",
    "        self.nodes = []\n",
    "        self.steps = [0]\n",
    "        self.leaf = 0\n",
    "        self.std = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,labels,X,feature_ids):\n",
    "        \n",
    "        self.split_result = 0\n",
    "        self.split = 0 #which column / which feature id\n",
    "        self.feature_ids = feature_ids\n",
    "        self.labels = labels\n",
    "        self.X = X\n",
    "        self.nodes = []\n",
    "        self.steps = []\n",
    "        self.variance = []\n",
    "        self.std = []\n",
    "        self.thresholds = []\n",
    "        \n",
    "        self.leaf = 0 #true or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X,labels,column,bottom,top):\n",
    "    \n",
    "    #Return a portion of the dataset, which's attributes is in a certain\n",
    "\n",
    "\n",
    "    sub_label = [labels[x] for x in range(len(labels)) if X[x][column]<top and X[x][column]>=bottom]\n",
    "    sub_X = [X[x] for x in range(len(X)) if X[x][column]<top and X[x][column]>=bottom]\n",
    "\n",
    "        \n",
    "    return [sub_X,sub_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_std(data):\n",
    "    \n",
    "    #print(data)\n",
    "    mean = sum(data)/len(data)\n",
    "    \n",
    "    variance = 0\n",
    "    \n",
    "    for i in data:\n",
    "        variance += (i-mean)**2\n",
    "    \n",
    "    \n",
    "    return math.sqrt(variance/len(data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dist(data1,data2):\n",
    "\n",
    "    d1 = sum(data1)/len(data1)\n",
    "    d2 = sum(data2)/len(data2)\n",
    "    return abs(d2-d1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_distance(sliced_data,column):\n",
    "    \n",
    "    dist = 0\n",
    "    min_dist = -1\n",
    "    index1 = -1\n",
    "    index2 = -1\n",
    "    \n",
    "    #determine what to merge by the standard deviation\n",
    "    \n",
    "    for i in range(len(sliced_data)-1):\n",
    "\n",
    "            dist = 0\n",
    "\n",
    "            X = sliced_data[i][0]\n",
    "            X2 = sliced_data[i+1][0]\n",
    "            X = [ X[j][column] for j in range(len(X)) ] \n",
    "            X2 = [ X2[j][column] for j in range(len(X2)) ]\n",
    "            \n",
    "                \n",
    "            #dist = abs(calculate_std(sliced_data[i][1])-calculate_std(sliced_data[i+1][1]))\n",
    "            #dist = abs(calculate_std(X)-calculate_std(X2))\n",
    "            dist = calculate_dist(X,X2)\n",
    "            #dist = calculate_dist(sliced_data[i][1],sliced_data[i+1][1])\n",
    "\n",
    "\n",
    "            #dist /=len(sliced_data[i][0][0]) \n",
    "            if(min_dist == -1):\n",
    "                min_dist = dist\n",
    "                index1 = i\n",
    "                index2 = i+1\n",
    "            if(dist<min_dist):\n",
    "                min_dist = dist\n",
    "                index1 = i\n",
    "                index2 = i+1\n",
    "    \n",
    "    return index1,index2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(sliced_data,column):\n",
    "    \n",
    "   \n",
    "\n",
    "    index1,index2 = find_min_distance(sliced_data,column)\n",
    "    \n",
    "\n",
    "    sliced_data[index1][0] = sliced_data[index1][0]+sliced_data[index2][0]\n",
    "    sliced_data[index1][1] = sliced_data[index1][1]+sliced_data[index2][1]\n",
    "\n",
    "   \n",
    "    \n",
    "    sliced_data.pop(index2)\n",
    "\n",
    "    return sliced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_merge(sliced_data,index,std,column):\n",
    "    \n",
    "   \n",
    "\n",
    "    #index1,index2 = find_min_distance(sliced_data,column)\n",
    "    dist_local = 0\n",
    "\n",
    "    for i in range(len(sliced_data[0][0][0])):\n",
    "\n",
    "        X = sliced_data[index][0]\n",
    "        X2 = sliced_data[index+1][0]\n",
    "        #features = [ X[j][i] for j in range(len(X)) ] + [ X2[j][i] for j in range(len(X2)) ]\n",
    "        #std_local += calculate_std(features)\n",
    "        dist_local += calculate_dist([ X[j][i] for j in range(len(X)) ],[ X2[j][i] for j in range(len(X2)) ])\n",
    "\n",
    "\n",
    "\n",
    "    if(dist_local <= std ) :\n",
    "\n",
    "        sliced_data[index][0] = sliced_data[index][0]+sliced_data[index+1][0]\n",
    "        sliced_data[index][1] = sliced_data[index][1]+sliced_data[index+1][1]\n",
    "        sliced_data.pop(index+1)\n",
    "        return sliced_data\n",
    "   \n",
    "    return sliced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_std_avg(features):\n",
    "        dist= 0\n",
    "\n",
    "\n",
    "        for i in range(len(features)-1):\n",
    "\n",
    "            dist += calculate_dist(features[i],features[i+1])\n",
    "\n",
    "        dist = dist/len(features)\n",
    "\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features2(sliced_data,column):#return attribute vetctor for each cluster\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for i in sliced_data:\n",
    "        features.append([ i[0][j][column] for j in range(len(i[0])) ])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X,labels,column):#Az std valójában distance\n",
    "    \n",
    "\n",
    "    sliced_data = [[ [x] , [y] ] for x,y in zip(X,labels)]\n",
    "\n",
    "    \n",
    "\n",
    "    #features = [ [X[j][column]] for j in range(len(X)) ] \n",
    "    labels = [ [j] for j in labels ] \n",
    "\n",
    "\n",
    "    std = 0\n",
    "\n",
    "    for i in range(len(sliced_data[0][0][0])):\n",
    "        std += calculate_std_avg(get_features2(sliced_data,i))\n",
    "\n",
    "\n",
    "    index = -1\n",
    "    l = 0\n",
    "\n",
    "    while(len(sliced_data)>=20):\n",
    "\n",
    "        index += 1\n",
    "        if(index>=len(sliced_data)-1):\n",
    "            index = 0\n",
    "            if(len(sliced_data) == l):\n",
    "                break\n",
    "            else:\n",
    "                l = len(sliced_data)\n",
    "            std = 0\n",
    "            for i in range(len(sliced_data[0][0][0])):\n",
    "                std += calculate_std_avg(get_features2(sliced_data,i))\n",
    "            \n",
    "            \n",
    "\n",
    "        sliced_data = pre_merge(sliced_data,index,std,column)\n",
    "        \n",
    "\n",
    "    return sliced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(X,labels,feature_ids,steps,div):\n",
    "    \n",
    "    step = -1\n",
    "\n",
    "    features = 0 \n",
    "    svalue = 0\n",
    "    \n",
    "    min_error = -1\n",
    "    min_sliced_data = []\n",
    "    min_regressions = []\n",
    "    min_steps = -1\n",
    "    min_column = -1\n",
    "\n",
    "\n",
    "\n",
    "    for column in feature_ids:\n",
    "            \n",
    "            \n",
    "            X,labels = sort_f(X,labels,column)        \n",
    "\n",
    "            if(steps[column] > 8 ):\n",
    "                    continue\n",
    "\n",
    "\n",
    "            sliced_data = preprocess(X,labels,column)\n",
    "           \n",
    "            while(len(sliced_data)>div):\n",
    "\n",
    "                sliced_data = merge(sliced_data,column)\n",
    "\n",
    "            \n",
    "            error = 0\n",
    "            for i in range(len(sliced_data)):\n",
    "                \n",
    "                error += calculate_std(sliced_data[i][1])\n",
    "           \n",
    "            if(min_error == -1):\n",
    "                min_sliced_data = sliced_data\n",
    "                \n",
    "                min_steps = step\n",
    "                min_column = column\n",
    "                min_error = error\n",
    "                continue\n",
    "            #choose the splited data with the minimum error\n",
    "            if(error<min_error):\n",
    "                min_sliced_data = sliced_data\n",
    "                min_error = error\n",
    "                min_steps = step\n",
    "                min_column = column\n",
    "    \n",
    "    #return split,split_value\n",
    "    steps[min_column] += 1\n",
    "    \n",
    "    return min_sliced_data,min_column,steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X,feature_ids,labels,leaf_size,limit,div,depth,steps,X_train,y_train):\n",
    "    \n",
    "    #find the best split for sub_nodes\n",
    "    #return sub_nodes\n",
    "    split = 0 \n",
    "    sub_nodes = []\n",
    "    \n",
    "    st = steps.copy()\n",
    "\n",
    "    #get the best split \n",
    "    split_data,column,st = find_best_split(X,labels,feature_ids,st,div)\n",
    "\n",
    "    \n",
    "    #create objects and inicialize them\n",
    "    for i in split_data:\n",
    "        \n",
    "        node = Node(i[1],i[0],feature_ids)\n",
    "        node.split = column \n",
    "\n",
    "        node.split_result = i[0][-1][column]\n",
    "        node.depth = depth\n",
    "        \n",
    "        node.top =   max([x[column] for x in node.X ])\n",
    "        node.bottom = min([x[column] for x in node.X ])\n",
    "\n",
    "        for j in range(len(node.X[0])):\n",
    "            node.thresholds.append([min([x[j] for x in node.X ]),max([x[j] for x in node.X ])])\n",
    "\n",
    "        node.steps = st\n",
    "\n",
    "        node.std.append(calculate_std(node.labels))\n",
    "\n",
    "        \n",
    "        if(len(node.labels) <= leaf_size or calculate_std(node.labels)<limit):\n",
    "            node.leaf = 1\n",
    "\n",
    "            \n",
    "        else:\n",
    "            node.leaf = 0\n",
    "            \n",
    "        sub_nodes.append(node)\n",
    "    \n",
    "    if(depth == 2000):\n",
    "        for i in sub_nodes:\n",
    "            i.leaf = 1\n",
    "        return sub_nodes\n",
    "    \n",
    "    depth +=1\n",
    "\n",
    "    leaf =  0\n",
    "    for i in sub_nodes:\n",
    "        if(i.leaf == 1):\n",
    "            leaf +=1\n",
    "            \n",
    "    if(leaf == len(sub_nodes)):\n",
    "        for i in sub_nodes:\n",
    "\n",
    "            if(calculate_std(i.labels)>=100):\n",
    "\n",
    "                print(calculate_std(i.labels),len(i.labels))\n",
    "\n",
    "            \n",
    "        return sub_nodes\n",
    "  \n",
    "    else:\n",
    "        for node in sub_nodes:\n",
    "\n",
    "            if(node.leaf == 0):\n",
    "\n",
    "                node.nodes = build_tree(node.X,node.feature_ids,node.labels,leaf_size,limit,div,depth,node.steps,X_train,y_train)\n",
    "\n",
    "\n",
    "    return sub_nodes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicialize(X,feature_names,labels,leaf_size,limit,div):\n",
    "    \n",
    "    depth = 1\n",
    "    feature_ids = [x for x in range(len(feature_names))]\n",
    "    tree = Tree(X,feature_names,labels)\n",
    "    \n",
    "    steps = []\n",
    "    for i in feature_ids:\n",
    "        steps.append(0)\n",
    "    #start building tree\n",
    "    tree.nodes = build_tree(X,feature_ids,labels,leaf_size,limit,div,depth,steps,X,labels)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2938802242279053\n",
      "-------------------------------------------------------\n",
      "1.4639387130737305\n",
      "-------------------------------------------------------\n",
      "1.486908197402954\n",
      "-------------------------------------------------------\n",
      "1.440079689025879\n",
      "-------------------------------------------------------\n",
      "0.014581441879272461\n",
      "-------------------------------------------------------\n",
      "0.009378910064697266\n",
      "-------------------------------------------------------\n",
      "0.0060575008392333984\n",
      "-------------------------------------------------------\n",
      "0.005351543426513672\n",
      "-------------------------------------------------------\n",
      "25.388563871383667\n",
      "-------------------------------------------------------\n",
      "12.848352670669556\n",
      "-------------------------------------------------------\n",
      "7.490605354309082\n",
      "-------------------------------------------------------\n",
      "6.552295446395874\n",
      "-------------------------------------------------------\n",
      "4.672508001327515\n",
      "-------------------------------------------------------\n",
      "3.2896182537078857\n",
      "-------------------------------------------------------\n",
      "2.5632381439208984\n",
      "-------------------------------------------------------\n",
      "2.0396902561187744\n"
     ]
    }
   ],
   "source": [
    "forest = []\n",
    "times = []\n",
    "\n",
    "divide = [2,3,4,5]\n",
    "counter = 0\n",
    "\n",
    "for i in all_data:\n",
    "    f = []\n",
    "    t = []\n",
    "\n",
    "\n",
    "    if(counter == 0):\n",
    "        size =20\n",
    "        var = 0.5\n",
    "    if(counter == 1):\n",
    "        size =5\n",
    "        var = 0.2\n",
    "    if(counter == 2):\n",
    "        size =20\n",
    "        var = 0.5\n",
    "    if(counter == 3):\n",
    "        size = 20\n",
    "        var = 1\n",
    "\n",
    "\n",
    "    for j in divide:\n",
    "       \n",
    "        print(\"-------------------------------------------------------\")\n",
    "\n",
    "\n",
    "        start = time.time()\n",
    "        tree = inicialize(i[0],i[-1],i[2],size,var,j)\n",
    "        end = time.time()\n",
    "        f.append(tree)\n",
    "        print(end-start)\n",
    "        t.append(end-start)\n",
    "        \n",
    "    counter+=1\n",
    "    forest.append(f)\n",
    "    times.append(t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node,value,thresholds,weight):\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    if(node.leaf == 1 ):\n",
    "\n",
    "\n",
    "        p = sum(node.labels)/len(node.labels)\n",
    "\n",
    "        X = []\n",
    "        #error = 0\n",
    "\n",
    "        for i in range(len(node.X[0])):\n",
    "\n",
    "         \n",
    "            X.append(sum([ ((node.X[j][i]-thresholds[i][0])/(thresholds[i][1]-thresholds[i][0])) * weight[i]  for j in range(len(node.X)) ]) )\n",
    "    \n",
    "        X = [x / len(node.X) for x in X]\n",
    "        \n",
    "        #print(X,p)\n",
    "        error = 0\n",
    "\n",
    "        for i in range(len(X)):\n",
    "\n",
    "            error +=  abs(X[i]- ((value[i]-thresholds[i][0])/(thresholds[i][1]-thresholds[i][0])) * weight[i] )\n",
    "        \n",
    "\n",
    "        p=[p,error]\n",
    "        \n",
    "        return p\n",
    "    else:\n",
    "        \n",
    "        c=0\n",
    "        \n",
    "        p = 0\n",
    "        \n",
    "        values = []\n",
    "        for i in node.nodes:\n",
    "\n",
    "            if (i.top>=value[i.split] and i.bottom<=value[i.split]  ):\n",
    "\n",
    "                c+=1\n",
    "                \n",
    "                p = predict(i,value,thresholds,weight)\n",
    "\n",
    "                for k in p:\n",
    "                    values.append(k)\n",
    "        if(c == 0  ):\n",
    "           \n",
    "\n",
    "            p = sum(node.labels)/len(node.labels)\n",
    "\n",
    "            X = []\n",
    "            #error = 0\n",
    "            for i in range(len(node.X[0])):\n",
    "                X.append(sum([ ((node.X[j][i]-thresholds[i][0])/(thresholds[i][1]-thresholds[i][0])) * weight[i]  for j in range(len(node.X)) ]) )\n",
    "\n",
    "\n",
    "            X = [x /len(node.X) for x in X]\n",
    "    \n",
    "            error = 0\n",
    "        \n",
    "            for i in range(len(X)):\n",
    "                error +=  abs(X[i]- ((value[i]-thresholds[i][0])/(thresholds[i][1]-thresholds[i][0])) * weight[i] )\n",
    "\n",
    "            \n",
    "            p=[p,error]\n",
    "\n",
    "            return p\n",
    "\n",
    "        return values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold(node):\n",
    "\n",
    "    if(node.leaf == 1):\n",
    "        return node.steps,node.depth\n",
    "\n",
    "\n",
    "    thresholds = [0] * len(node.X[0])\n",
    "    \n",
    "    for i in node.nodes:\n",
    "        s,depth = get_threshold(i)\n",
    "\n",
    "        for j in range(len(s)):\n",
    "            thresholds[j] += s[j]\n",
    "    return thresholds,depth\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.2938802242279053, 1.4639387130737305, 1.486908197402954, 1.440079689025879], [0.014581441879272461, 0.009378910064697266, 0.0060575008392333984, 0.005351543426513672], [25.388563871383667, 12.848352670669556, 7.490605354309082, 6.552295446395874], [4.672508001327515, 3.2896182537078857, 2.5632381439208984, 2.0396902561187744]]\n",
      "[237.92263276218355, 514.1752805275729, 97.05599282080658, 209.05028947429543, 2.3214285714285716, 1.688888888888889, 2.743650793650793, 2.743650793650793, 522.6243941362828, 534.293436061541, 534.1472034601878, 595.0155008910308, 5725.147641982945, 5975.497395587674, 6312.75636201757, 6460.951125094305]\n",
      "[4019, 4019, 4019, 4019, 60, 60, 60, 60, 5707.0, 5707.0, 5707.0, 5707.0, 620464.5291393183, 620464.5291393183, 620464.5291393183, 620464.5291393183]\n",
      "[[0.08390730799113708, 0.13911573842969793, 0.036498573305620396, 0.06301990647254917], [0.07011054421768707, 0.03845267489711934, 0.06920569832871423, 0.06920569832871423], [0.48393053658682395, 0.536819592390365, 0.5198509680470641, 0.594171203816516], [14.676599841528544, 15.633760855185505, 17.70788045500832, 18.601197389423852]]\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(times)\n",
    "predicted_value = []#predicted points\n",
    "difference = []\n",
    "MSE = []\n",
    "sum_y = []\n",
    "\n",
    "#all_difference = []\n",
    "all_mse = []\n",
    "all_std = []\n",
    "#for each tree we calculate the mean squared error\n",
    "\n",
    "\n",
    "\n",
    "for v in range(len(forest)):\n",
    "    MSE = []\n",
    "    counter = 0\n",
    "    for i in forest[v]:\n",
    "        counter += 1\n",
    "        j = all_data[v]\n",
    "        \n",
    "        X_test = j[1]\n",
    "        y_test = j[3]\n",
    "        pv = []\n",
    "        error = 0\n",
    "        mse = 0\n",
    "        l = 0\n",
    "        thresholds,depth = get_threshold(i)\n",
    "        thresholds = [x/depth for x in thresholds]\n",
    "        \n",
    "        for k in range(len(X_test)): \n",
    "\n",
    "\n",
    "            pr = predict(i,X_test[k],all_limits[v],thresholds)\n",
    "\n",
    "            p = 0\n",
    "\n",
    "            prev = 1000000000000\n",
    "            if(pr[0] != 0):\n",
    "\n",
    "                for f in range(0,len(pr)-1,2):\n",
    "                    if(pr[f+1]<prev):\n",
    "                        prev = pr[f+1]\n",
    "                        p = pr[f]\n",
    "\n",
    "\n",
    "            error += abs(y_test[k]-p)\n",
    "\n",
    "            mse += (y_test[k]-p)**2\n",
    "            pv.append(p)\n",
    "           \n",
    "\n",
    "\n",
    "        sum_y.append(sum(y_test))\n",
    "        predicted_value.append(pv)\n",
    "        difference.append(error)\n",
    "        MSE.append(mse/len(X_test))\n",
    "        #MSE.append(mse/l)\n",
    "\n",
    "    all_mse.append(MSE)\n",
    "    \n",
    "    \n",
    "print(difference)\n",
    "print(sum_y)\n",
    "\n",
    "print(all_mse)\n",
    "'''with open(\"Results/difference_rtn.csv\", 'a',newline='') as f:\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write a row to the csv file\n",
    "    for row in all_mse:\n",
    "        writer.writerow(row)\n",
    "        \n",
    "with open(\"Results/times_rtn.csv\", 'a',newline='') as f:\n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write a row to the csv file\n",
    "    \n",
    "    for row in times:\n",
    "        \n",
    "        writer.writerow(row)'''\n",
    "\n",
    "print(len(predicted_value[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
